{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "# Define the gpu  on the gpu machine\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>dataset</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seeking All Things Brilliant \"I want people to...</td>\n",
       "      <td>Other</td>\n",
       "      <td>CORE</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Meet Orchid du Bois I first met Hayley Mowday ...</td>\n",
       "      <td>Other</td>\n",
       "      <td>CORE</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text labels dataset language\n",
       "0  Seeking All Things Brilliant \"I want people to...  Other    CORE  English\n",
       "1  Meet Orchid du Bois I first met Hayley Mowday ...  Other    CORE  English"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1772 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1810 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 1772/1772 [00:09<00:00, 189.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "699465\n"
     ]
    }
   ],
   "source": [
    "# Import the train dataset\n",
    "train = load_dataset(\"TajaKuzman/X-GENRE-multilingual-text-genre-dataset\", \"train\")\n",
    "\n",
    "# To open as Pandas DataFrame:\n",
    "train_df = pd.DataFrame(train[\"train\"])\n",
    "\n",
    "display(train_df.head(2))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "\n",
    "# Tokenize the train dataset\n",
    "tokens_train = []\n",
    "integers_train = []\n",
    "token_list_train = []\n",
    "\n",
    "for text in tqdm(train_df.text.to_list()):\n",
    "\tencoded_text = tokenizer(text)\n",
    "\t# Take all tokens_train, except the beginning (<s>) and end (</s>) token\n",
    "\tcurrent_tokens_train = tokenizer.convert_ids_to_tokens(encoded_text.input_ids)[1:-1]\n",
    "\ttokens_train.append(current_tokens_train)\n",
    "\ttoken_list_train.extend(current_tokens_train)\n",
    "\tintegers_train.append(encoded_text.input_ids[1:-1])\n",
    "\n",
    "train_df[\"tokens_train\"] = tokens_train\n",
    "train_df[\"token_ids\"] = integers_train\n",
    "\n",
    "#print(token_list_train[:10])\n",
    "#print(len(token_list_train))\n",
    "\n",
    "# Create a list of tokens, where we take only the first 512 tokens\n",
    "train_tokens_shortened = []\n",
    "\n",
    "for i in train_df[\"tokens_train\"].to_list():\n",
    "\ttrain_tokens_shortened.extend(i[:512])\n",
    "\n",
    "print(len(train_tokens_shortened))\n",
    "\n",
    "train_df.head(3)\n",
    "\n",
    "# Save the tokenized version\n",
    "train_df.to_json(\"datasets/tokenized_datasets/X-GENRE-train-tokenized.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mt', 'el', 'tr', 'sq', 'is', 'uk', 'ca', 'mk', 'hr', 'sl'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the final dataset with test sets\n",
    "with open(\"manual-annotations/multilingual-genre-annotated-test-set.json\") as main_file:\n",
    "\tmain_dict = json.load(main_file)\n",
    "\n",
    "main_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing text.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/80 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (768 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 80/80 [00:00<00:00, 315.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁Angel', 'o', '▁Che', 't', 'cuti', ',', '▁se', '▁j', 'kun', '▁qe']\n",
      "All tokens:\n",
      "39040\n",
      "Calculating overlap.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39040/39040 [01:21<00:00, 478.57it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens that overlap: 31899\n",
      "Percentage of overlap: 0.8170850409836066\n",
      "Tokenizing text.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/80 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (875 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 80/80 [00:00<00:00, 485.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁Ενημέρωση', '▁του', '▁Pegasus', '▁Esti', 'asi', '▁με', '▁τις', '▁εισ', 'ερ', 'χ']\n",
      "All tokens:\n",
      "31240\n",
      "Calculating overlap.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31240/31240 [03:27<00:00, 150.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens that overlap: 5043\n",
      "Percentage of overlap: 0.16142765685019206\n",
      "Tokenizing text.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/80 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (631 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 80/80 [00:00<00:00, 438.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁A', 'Ö', 'L', '▁Der', 's', '▁Seçim', 'i', '▁ve', '▁Sınav', '▁Giriş']\n",
      "All tokens:\n",
      "29578\n",
      "Calculating overlap.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29578/29578 [02:15<00:00, 218.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens that overlap: 15425\n",
      "Percentage of overlap: 0.5215024680505781\n",
      "Tokenizing text.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/80 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 80/80 [00:00<00:00, 510.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁Blog', '▁“', 'U', 'në', '▁të', '▁kam', '▁dashur', '▁me', '▁një', '▁dashuri']\n",
      "All tokens:\n",
      "26769\n",
      "Calculating overlap.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26769/26769 [02:10<00:00, 205.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens that overlap: 16216\n",
      "Percentage of overlap: 0.605775337143711\n",
      "Tokenizing text.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/80 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (920 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 80/80 [00:00<00:00, 439.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁[', 'is', ']', '▁Því', '▁er', '▁við', '▁hæ', 'fi', '▁að', '▁reg']\n",
      "All tokens:\n",
      "29644\n",
      "Calculating overlap.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29644/29644 [02:09<00:00, 228.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens that overlap: 15343\n",
      "Percentage of overlap: 0.5175752260153825\n",
      "Tokenizing text.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/80 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1002 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 80/80 [00:00<00:00, 416.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁Не', 'стандарт', 'ний', '▁підхід', '▁для', '▁виготовлення', '▁Ак', 'вар', 'і', 'у']\n",
      "All tokens:\n",
      "31677\n",
      "Calculating overlap.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31677/31677 [03:28<00:00, 151.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens that overlap: 4963\n",
      "Percentage of overlap: 0.15667519020109227\n",
      "Tokenizing text.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/80 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (576 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 80/80 [00:00<00:00, 577.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁P', 'à', 'gine', 's', '▁En', 'fei', 'nada', '▁Porto', '▁uns', '▁dies']\n",
      "All tokens:\n",
      "27544\n",
      "Calculating overlap.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27544/27544 [01:08<00:00, 400.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens that overlap: 20517\n",
      "Percentage of overlap: 0.7448809178042405\n",
      "Tokenizing text.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/80 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (816 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 80/80 [00:00<00:00, 588.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁Ек', 'шу', 'ли', ',', '▁T', 'CL', '▁ги', '▁прави', '▁смартфон', 'овите']\n",
      "All tokens:\n",
      "27639\n",
      "Calculating overlap.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27639/27639 [03:22<00:00, 136.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens that overlap: 4035\n",
      "Percentage of overlap: 0.14598936285683273\n",
      "Tokenizing text.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/80 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 80/80 [00:00<00:00, 677.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁O', '▁proizvod', 'u', '▁Color', '▁Trans', 'former', ',', '▁za', '▁pamet', 'no']\n",
      "All tokens:\n",
      "26546\n",
      "Calculating overlap.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26546/26546 [01:05<00:00, 408.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens that overlap: 21808\n",
      "Percentage of overlap: 0.8215173660815188\n",
      "Tokenizing text.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/80 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (804 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 80/80 [00:00<00:00, 656.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁Kita', 'jsko', '▁mesto', '▁duhov', '▁V', '▁Notranj', 'i', '▁Mongol', 'iji', '▁raste']\n",
      "All tokens:\n",
      "26292\n",
      "Calculating overlap.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26292/26292 [00:45<00:00, 573.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens that overlap: 25616\n",
      "Percentage of overlap: 0.9742887570363609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define an array of token overlap\n",
    "token_overlap_results = {}\n",
    "\n",
    "# Loop through the datasets and calculate token overlap\n",
    "for lang in list(main_dict.keys()):\n",
    "\tdf = pd.DataFrame(main_dict[lang][\"dataset\"])\n",
    "\n",
    "\ttokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "\n",
    "\ttokens = []\n",
    "\tintegers = []\n",
    "\ttoken_list = []\n",
    "\n",
    "\tprint(\"Tokenizing text.\")\n",
    "\n",
    "\tfor text in tqdm(df.text.to_list()):\n",
    "\t\tencoded_text = tokenizer(text)\n",
    "\t\t# Take all tokens, except the beginning (<s>) and end (</s>) token\n",
    "\t\tcurrent_tokens = tokenizer.convert_ids_to_tokens(encoded_text.input_ids)[1:-1]\n",
    "\t\t# Shorten the list to 512, as tokens after that were not observed by the classifier\n",
    "\t\tcurrent_tokens = current_tokens[:512]\n",
    "\t\ttokens.append(current_tokens)\n",
    "\t\ttoken_list.extend(current_tokens)\n",
    "\t\tintegers.append(encoded_text.input_ids[1:-1][:512])\n",
    "\n",
    "\tdf[\"tokens\"] = tokens\n",
    "\tdf[\"token_ids\"] = integers\n",
    "\n",
    "\tprint(token_list[:10])\n",
    "\tprint(\"All tokens:\")\n",
    "\tprint(len(token_list))\n",
    "\n",
    "\t# See how many tokens overlap\n",
    "\toverlap_counter = 0\n",
    "\n",
    "\tprint(\"Calculating overlap.\")\n",
    "\n",
    "\t# Save tokens that overlap for further inspection\n",
    "\toverlap_token_list = []\n",
    "\n",
    "\t#overlap_counter = sum(1 for element in token_list if element in train_tokens_shortened)\n",
    "\tfor token in tqdm(token_list):\n",
    "\t\tif token in train_tokens_shortened:\n",
    "\t\t\toverlap_counter += 1\n",
    "\t\t\toverlap_token_list.append(token)\n",
    "\n",
    "\t# Out of all tokens, how many overlap?\n",
    "\toverlap_per = overlap_counter/len(token_list)\n",
    "\n",
    "\tprint(f\"Number of tokens that overlap: {overlap_counter}\")\n",
    "\tprint(f\"Percentage of overlap: {overlap_per}\")\n",
    "\n",
    "\t# Update the dataset in the dictionary\n",
    "\tmain_dict[lang][\"dataset\"] = df.to_dict()\n",
    "\n",
    "\t# Add the list of all tokens to the dictionary\n",
    "\tmain_dict[lang][\"token_overlap\"] = {\"overlap_percentage\":overlap_per, \"token_list\": token_list, \"overlap_token_list\":overlap_token_list}\n",
    "\n",
    "\t# Add to the results\n",
    "\ttoken_overlap_results[lang] = {\"percentage\": overlap_per, \"overlap_list\": overlap_token_list}\n",
    "\n",
    "\t# Convert tokens back to words\n",
    "\t#print(tokenizer.convert_tokens_to_string(tokens))\n",
    "\n",
    "# Inspect the results\n",
    "overlap_df = pd.DataFrame(token_overlap_results)\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>percentage</th>\n",
       "      <th>overlap_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mt</th>\n",
       "      <td>0.817085</td>\n",
       "      <td>[▁Angel, o, ▁Che, t, ,, ▁se, ▁j, kun, d, u, ▁p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>el</th>\n",
       "      <td>0.161428</td>\n",
       "      <td>[asi, asi, ,, ,, ▁Re, ception, ., ▁driver, ▁es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr</th>\n",
       "      <td>0.521502</td>\n",
       "      <td>[▁A, L, ▁Der, s, i, ▁ve, ▁Beli, r, leme, ▁S, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sq</th>\n",
       "      <td>0.605775</td>\n",
       "      <td>[▁Blog, ▁“, U, ▁kam, ▁me, jet, .”, ▁Jer, ▁31, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>0.517575</td>\n",
       "      <td>[▁[, is, ], ▁er, fi, ▁reg, ▁sett, ar, lag, sin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uk</th>\n",
       "      <td>0.156675</td>\n",
       "      <td>[., ,, ,, ?, ▁-, ., ?, ▁-, ', ., ,, ., ▁, ▁(, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca</th>\n",
       "      <td>0.744881</td>\n",
       "      <td>[▁P, à, gine, s, ▁En, nada, ▁Porto, ▁uns, ▁die...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mk</th>\n",
       "      <td>0.145989</td>\n",
       "      <td>[,, ▁T, CL, ,, ▁T, CL, :, ▁Alca, tel, ▁Mobile,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hr</th>\n",
       "      <td>0.821517</td>\n",
       "      <td>[▁O, ▁proizvod, u, ▁Color, ▁Trans, ,, ▁za, ▁pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sl</th>\n",
       "      <td>0.974289</td>\n",
       "      <td>[▁Kita, jsko, ▁mesto, ▁duhov, ▁V, ▁Notranj, i,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   percentage                                       overlap_list\n",
       "mt   0.817085  [▁Angel, o, ▁Che, t, ,, ▁se, ▁j, kun, d, u, ▁p...\n",
       "el   0.161428  [asi, asi, ,, ,, ▁Re, ception, ., ▁driver, ▁es...\n",
       "tr   0.521502  [▁A, L, ▁Der, s, i, ▁ve, ▁Beli, r, leme, ▁S, h...\n",
       "sq   0.605775  [▁Blog, ▁“, U, ▁kam, ▁me, jet, .”, ▁Jer, ▁31, ...\n",
       "is   0.517575  [▁[, is, ], ▁er, fi, ▁reg, ▁sett, ar, lag, sin...\n",
       "uk   0.156675  [., ,, ,, ?, ▁-, ., ?, ▁-, ', ., ,, ., ▁, ▁(, ...\n",
       "ca   0.744881  [▁P, à, gine, s, ▁En, nada, ▁Porto, ▁uns, ▁die...\n",
       "mk   0.145989  [,, ▁T, CL, ,, ▁T, CL, :, ▁Alca, tel, ▁Mobile,...\n",
       "hr   0.821517  [▁O, ▁proizvod, u, ▁Color, ▁Trans, ,, ▁za, ▁pa...\n",
       "sl   0.974289  [▁Kita, jsko, ▁mesto, ▁duhov, ▁V, ▁Notranj, i,..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlap_df = pd.DataFrame(token_overlap_results).transpose()\n",
    "overlap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁Angel\n"
     ]
    }
   ],
   "source": [
    "for token in overlap_df[\"overlap_list\"].to_list()[0][:2]:\n",
    "\tif len(token) > 1:\n",
    "\t\tnon_short_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>percentage</th>\n",
       "      <th>overlap_list</th>\n",
       "      <th>non_short</th>\n",
       "      <th>non_short_per</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mt</th>\n",
       "      <td>0.817085</td>\n",
       "      <td>[▁Angel, o, ▁Che, t, ,, ▁se, ▁j, kun, d, u, ▁p...</td>\n",
       "      <td>23083</td>\n",
       "      <td>0.723628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>el</th>\n",
       "      <td>0.161428</td>\n",
       "      <td>[asi, asi, ,, ,, ▁Re, ception, ., ▁driver, ▁es...</td>\n",
       "      <td>1883</td>\n",
       "      <td>0.373389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr</th>\n",
       "      <td>0.521502</td>\n",
       "      <td>[▁A, L, ▁Der, s, i, ▁ve, ▁Beli, r, leme, ▁S, h...</td>\n",
       "      <td>11141</td>\n",
       "      <td>0.722269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sq</th>\n",
       "      <td>0.605775</td>\n",
       "      <td>[▁Blog, ▁“, U, ▁kam, ▁me, jet, .”, ▁Jer, ▁31, ...</td>\n",
       "      <td>12459</td>\n",
       "      <td>0.768315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>0.517575</td>\n",
       "      <td>[▁[, is, ], ▁er, fi, ▁reg, ▁sett, ar, lag, sin...</td>\n",
       "      <td>10915</td>\n",
       "      <td>0.711399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uk</th>\n",
       "      <td>0.156675</td>\n",
       "      <td>[., ,, ,, ?, ▁-, ., ?, ▁-, ', ., ,, ., ▁, ▁(, ...</td>\n",
       "      <td>1258</td>\n",
       "      <td>0.253476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca</th>\n",
       "      <td>0.744881</td>\n",
       "      <td>[▁P, à, gine, s, ▁En, nada, ▁Porto, ▁uns, ▁die...</td>\n",
       "      <td>15657</td>\n",
       "      <td>0.763123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mk</th>\n",
       "      <td>0.145989</td>\n",
       "      <td>[,, ▁T, CL, ,, ▁T, CL, :, ▁Alca, tel, ▁Mobile,...</td>\n",
       "      <td>1270</td>\n",
       "      <td>0.314746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hr</th>\n",
       "      <td>0.821517</td>\n",
       "      <td>[▁O, ▁proizvod, u, ▁Color, ▁Trans, ,, ▁za, ▁pa...</td>\n",
       "      <td>17678</td>\n",
       "      <td>0.810620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sl</th>\n",
       "      <td>0.974289</td>\n",
       "      <td>[▁Kita, jsko, ▁mesto, ▁duhov, ▁V, ▁Notranj, i,...</td>\n",
       "      <td>21567</td>\n",
       "      <td>0.841935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   percentage                                       overlap_list  non_short  \\\n",
       "mt   0.817085  [▁Angel, o, ▁Che, t, ,, ▁se, ▁j, kun, d, u, ▁p...      23083   \n",
       "el   0.161428  [asi, asi, ,, ,, ▁Re, ception, ., ▁driver, ▁es...       1883   \n",
       "tr   0.521502  [▁A, L, ▁Der, s, i, ▁ve, ▁Beli, r, leme, ▁S, h...      11141   \n",
       "sq   0.605775  [▁Blog, ▁“, U, ▁kam, ▁me, jet, .”, ▁Jer, ▁31, ...      12459   \n",
       "is   0.517575  [▁[, is, ], ▁er, fi, ▁reg, ▁sett, ar, lag, sin...      10915   \n",
       "uk   0.156675  [., ,, ,, ?, ▁-, ., ?, ▁-, ', ., ,, ., ▁, ▁(, ...       1258   \n",
       "ca   0.744881  [▁P, à, gine, s, ▁En, nada, ▁Porto, ▁uns, ▁die...      15657   \n",
       "mk   0.145989  [,, ▁T, CL, ,, ▁T, CL, :, ▁Alca, tel, ▁Mobile,...       1270   \n",
       "hr   0.821517  [▁O, ▁proizvod, u, ▁Color, ▁Trans, ,, ▁za, ▁pa...      17678   \n",
       "sl   0.974289  [▁Kita, jsko, ▁mesto, ▁duhov, ▁V, ▁Notranj, i,...      21567   \n",
       "\n",
       "    non_short_per  \n",
       "mt       0.723628  \n",
       "el       0.373389  \n",
       "tr       0.722269  \n",
       "sq       0.768315  \n",
       "is       0.711399  \n",
       "uk       0.253476  \n",
       "ca       0.763123  \n",
       "mk       0.314746  \n",
       "hr       0.810620  \n",
       "sl       0.841935  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect how many tokens are one character long\n",
    "\n",
    "counters = []\n",
    "pers = []\n",
    "\n",
    "for token_list_el in overlap_df[\"overlap_list\"].to_list():\n",
    "\tnon_short_counter = 0\n",
    "\tfor token in token_list_el:\n",
    "\t\tif len(token) > 1:\n",
    "\t\t\tnon_short_counter += 1\n",
    "\t\n",
    "\tcounters.append(non_short_counter)\n",
    "\tpers.append(non_short_counter/len(token_list_el))\n",
    "\n",
    "# Add to df\n",
    "overlap_df[\"non_short\"] = counters\n",
    "\n",
    "# Calculate the percentage of overlap tokens that have more than 1 character\n",
    "overlap_df[\"non_short_per\"] = pers\n",
    "\n",
    "overlap_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate token distribution - vector of values per tokens (how many times does each token occur) - create a dictionary with all tokens from train set and specific test set, iterate through the tokens and count how many times each ocurrs. Calculate cosine similarity.\n",
    "\n",
    "# Do this on label level as well to see whether this explains good performance on some of the labels for Maltese."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transliterate Cyrillic and Greek and see whether the overlap effect changes. If you find a proper library, you can also normalize specific letters (š -> s ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the extended json dict\n",
    "with open(\"manual-annotations/multilingual-genre-annotated-test-set.json\", \"w\") as file:\n",
    "\tjson.dump(main_dict, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crosslingual_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
