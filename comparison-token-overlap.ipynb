{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "# Define the gpu  on the gpu machine\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mt', 'el', 'tr', 'sq', 'is', 'uk', 'ca', 'mk', 'hr'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the final dataset with test sets\n",
    "with open(\"manual-annotations/multilingual-genre-annotated-test-set.json\") as main_file:\n",
    "\tmain_dict = json.load(main_file)\n",
    "\n",
    "main_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>text</th>\n",
       "      <th>translation</th>\n",
       "      <th>metadata</th>\n",
       "      <th>y_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CLASSLA-web.mk.1000486</td>\n",
       "      <td>Forum</td>\n",
       "      <td>Екшули, TCL ги прави смартфоновите, а TCL е см...</td>\n",
       "      <td>Ekshui, TCL makes smartphones, and TCL is hous...</td>\n",
       "      <td>CLASSLA-web.mk.1000486', 'domain': 'forum.carc...</td>\n",
       "      <td>Forum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CLASSLA-web.mk.1009071</td>\n",
       "      <td>News</td>\n",
       "      <td>Red Valentino прогнозира бура од принтови за с...</td>\n",
       "      <td>Red Valentino predicts a storm of prints for n...</td>\n",
       "      <td>CLASSLA-web.mk.1009071', 'domain': 'fashionel....</td>\n",
       "      <td>News</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  text_id y_pred  \\\n",
       "0  CLASSLA-web.mk.1000486  Forum   \n",
       "1  CLASSLA-web.mk.1009071   News   \n",
       "\n",
       "                                                text  \\\n",
       "0  Екшули, TCL ги прави смартфоновите, а TCL е см...   \n",
       "1  Red Valentino прогнозира бура од принтови за с...   \n",
       "\n",
       "                                         translation  \\\n",
       "0  Ekshui, TCL makes smartphones, and TCL is hous...   \n",
       "1  Red Valentino predicts a storm of prints for n...   \n",
       "\n",
       "                                            metadata y_true  \n",
       "0  CLASSLA-web.mk.1000486', 'domain': 'forum.carc...  Forum  \n",
       "1  CLASSLA-web.mk.1009071', 'domain': 'fashionel....   News  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the approach\n",
    "df = pd.DataFrame(main_dict[\"mk\"][\"dataset\"])\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (816 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 80/80 [00:00<00:00, 568.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁Ек', 'шу', 'ли', ',', '▁T', 'CL', '▁ги', '▁прави', '▁смартфон', 'овите']\n",
      "30387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>text</th>\n",
       "      <th>translation</th>\n",
       "      <th>metadata</th>\n",
       "      <th>y_true</th>\n",
       "      <th>tokens</th>\n",
       "      <th>token_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CLASSLA-web.mk.1000486</td>\n",
       "      <td>Forum</td>\n",
       "      <td>Екшули, TCL ги прави смартфоновите, а TCL е см...</td>\n",
       "      <td>Ekshui, TCL makes smartphones, and TCL is hous...</td>\n",
       "      <td>CLASSLA-web.mk.1000486', 'domain': 'forum.carc...</td>\n",
       "      <td>Forum</td>\n",
       "      <td>[▁Ек, шу, ли, ,, ▁T, CL, ▁ги, ▁прави, ▁смартфо...</td>\n",
       "      <td>[75430, 12213, 546, 4, 384, 37486, 1670, 10416...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CLASSLA-web.mk.1009071</td>\n",
       "      <td>News</td>\n",
       "      <td>Red Valentino прогнозира бура од принтови за с...</td>\n",
       "      <td>Red Valentino predicts a storm of prints for n...</td>\n",
       "      <td>CLASSLA-web.mk.1009071', 'domain': 'fashionel....</td>\n",
       "      <td>News</td>\n",
       "      <td>[▁Red, ▁Valentino, ▁прогноз, ира, ▁бур, а, ▁од...</td>\n",
       "      <td>[6096, 166361, 45404, 6790, 21623, 59, 338, 44...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CLASSLA-web.mk.1043814</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>Најголем фактор на ризик за развој на проширен...</td>\n",
       "      <td>The biggest risk factor for the development of...</td>\n",
       "      <td>CLASSLA-web.mk.1043814', 'domain': 'puls24.mk'}</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>[▁Најголем, ▁фактор, ▁на, ▁ризик, ▁за, ▁развој...</td>\n",
       "      <td>[238783, 25873, 29, 50641, 61, 25348, 29, 591,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  text_id       y_pred  \\\n",
       "0  CLASSLA-web.mk.1000486        Forum   \n",
       "1  CLASSLA-web.mk.1009071         News   \n",
       "2  CLASSLA-web.mk.1043814  Instruction   \n",
       "\n",
       "                                                text  \\\n",
       "0  Екшули, TCL ги прави смартфоновите, а TCL е см...   \n",
       "1  Red Valentino прогнозира бура од принтови за с...   \n",
       "2  Најголем фактор на ризик за развој на проширен...   \n",
       "\n",
       "                                         translation  \\\n",
       "0  Ekshui, TCL makes smartphones, and TCL is hous...   \n",
       "1  Red Valentino predicts a storm of prints for n...   \n",
       "2  The biggest risk factor for the development of...   \n",
       "\n",
       "                                            metadata       y_true  \\\n",
       "0  CLASSLA-web.mk.1000486', 'domain': 'forum.carc...        Forum   \n",
       "1  CLASSLA-web.mk.1009071', 'domain': 'fashionel....         News   \n",
       "2    CLASSLA-web.mk.1043814', 'domain': 'puls24.mk'}  Instruction   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [▁Ек, шу, ли, ,, ▁T, CL, ▁ги, ▁прави, ▁смартфо...   \n",
       "1  [▁Red, ▁Valentino, ▁прогноз, ира, ▁бур, а, ▁од...   \n",
       "2  [▁Најголем, ▁фактор, ▁на, ▁ризик, ▁за, ▁развој...   \n",
       "\n",
       "                                           token_ids  \n",
       "0  [75430, 12213, 546, 4, 384, 37486, 1670, 10416...  \n",
       "1  [6096, 166361, 45404, 6790, 21623, 59, 338, 44...  \n",
       "2  [238783, 25873, 29, 50641, 61, 25348, 29, 591,...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the XLM-R-base tokenizer over the dataset\n",
    "from transformers import AutoTokenizer, XLMRobertaModel\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "\n",
    "tokens = []\n",
    "integers = []\n",
    "token_list = []\n",
    "\n",
    "for text in tqdm(df.text.to_list()):\n",
    "\tencoded_text = tokenizer(text)\n",
    "\t# Take all tokens, except the beginning (<s>) and end (</s>) token\n",
    "\tcurrent_tokens = tokenizer.convert_ids_to_tokens(encoded_text.input_ids)[1:-1]\n",
    "\ttokens.append(current_tokens)\n",
    "\ttoken_list.extend(current_tokens)\n",
    "\tintegers.append(encoded_text.input_ids[1:-1])\n",
    "\n",
    "df[\"tokens\"] = tokens\n",
    "df[\"token_ids\"] = integers\n",
    "\n",
    "print(token_list[:10])\n",
    "print(len(token_list))\n",
    "\n",
    "df.head(3)\n",
    "\n",
    "# Convert tokens back to words\n",
    "#print(tokenizer.convert_tokens_to_string(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 14.2k/14.2k [00:00<00:00, 1.38MB/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>dataset</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seeking All Things Brilliant \"I want people to...</td>\n",
       "      <td>Other</td>\n",
       "      <td>CORE</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Meet Orchid du Bois I first met Hayley Mowday ...</td>\n",
       "      <td>Other</td>\n",
       "      <td>CORE</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abstract Objective: Reporting bias due to soci...</td>\n",
       "      <td>Information/Explanation</td>\n",
       "      <td>CORE</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In 2009 the song was the focus of a successful...</td>\n",
       "      <td>Information/Explanation</td>\n",
       "      <td>CORE</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QuotW This was the week when neither rumours o...</td>\n",
       "      <td>News</td>\n",
       "      <td>CORE</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767</th>\n",
       "      <td>Sound Pillow represents another way in which t...</td>\n",
       "      <td>Promotion</td>\n",
       "      <td>FTD</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1768</th>\n",
       "      <td>Night vision scopes have been a quite signific...</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>FTD</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1769</th>\n",
       "      <td>Personal stories - Leigh I was diagnosed over ...</td>\n",
       "      <td>Opinion/Argumentation</td>\n",
       "      <td>FTD</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1770</th>\n",
       "      <td>A few days ago , in a galaxy far , far away .....</td>\n",
       "      <td>Prose/Lyrical</td>\n",
       "      <td>FTD</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone - J. ...</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>FTD</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1772 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     Seeking All Things Brilliant \"I want people to...   \n",
       "1     Meet Orchid du Bois I first met Hayley Mowday ...   \n",
       "2     Abstract Objective: Reporting bias due to soci...   \n",
       "3     In 2009 the song was the focus of a successful...   \n",
       "4     QuotW This was the week when neither rumours o...   \n",
       "...                                                 ...   \n",
       "1767  Sound Pillow represents another way in which t...   \n",
       "1768  Night vision scopes have been a quite signific...   \n",
       "1769  Personal stories - Leigh I was diagnosed over ...   \n",
       "1770  A few days ago , in a galaxy far , far away .....   \n",
       "1771  Harry Potter and the Philosopher's Stone - J. ...   \n",
       "\n",
       "                       labels dataset language  \n",
       "0                       Other    CORE  English  \n",
       "1                       Other    CORE  English  \n",
       "2     Information/Explanation    CORE  English  \n",
       "3     Information/Explanation    CORE  English  \n",
       "4                        News    CORE  English  \n",
       "...                       ...     ...      ...  \n",
       "1767                Promotion     FTD  English  \n",
       "1768              Instruction     FTD  English  \n",
       "1769    Opinion/Argumentation     FTD  English  \n",
       "1770            Prose/Lyrical     FTD  English  \n",
       "1771              Instruction     FTD  English  \n",
       "\n",
       "[1772 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize also the train dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "train = load_dataset(\"TajaKuzman/X-GENRE-multilingual-text-genre-dataset\", \"train\")\n",
    "\n",
    "# To open as Pandas DataFrame:\n",
    "train_df = pd.DataFrame(train[\"train\"])\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1772/1772 [00:09<00:00, 186.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁See', 'king', '▁All', '▁Things', '▁Br', 'illian', 't', '▁\"', 'I', '▁want']\n",
      "2710819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>dataset</th>\n",
       "      <th>language</th>\n",
       "      <th>tokens_train</th>\n",
       "      <th>token_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seeking All Things Brilliant \"I want people to...</td>\n",
       "      <td>Other</td>\n",
       "      <td>CORE</td>\n",
       "      <td>English</td>\n",
       "      <td>[▁See, king, ▁All, ▁Things, ▁Br, illian, t, ▁\"...</td>\n",
       "      <td>[6872, 6048, 3164, 119175, 13008, 162076, 18, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Meet Orchid du Bois I first met Hayley Mowday ...</td>\n",
       "      <td>Other</td>\n",
       "      <td>CORE</td>\n",
       "      <td>English</td>\n",
       "      <td>[▁Meet, ▁Or, ch, id, ▁du, ▁Bo, is, ▁I, ▁first,...</td>\n",
       "      <td>[72626, 3347, 206, 532, 115, 2460, 164, 87, 51...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abstract Objective: Reporting bias due to soci...</td>\n",
       "      <td>Information/Explanation</td>\n",
       "      <td>CORE</td>\n",
       "      <td>English</td>\n",
       "      <td>[▁Abstract, ▁Object, ive, :, ▁Report, ing, ▁bi...</td>\n",
       "      <td>[233973, 134549, 5844, 12, 34798, 214, 333, 16...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                   labels  \\\n",
       "0  Seeking All Things Brilliant \"I want people to...                    Other   \n",
       "1  Meet Orchid du Bois I first met Hayley Mowday ...                    Other   \n",
       "2  Abstract Objective: Reporting bias due to soci...  Information/Explanation   \n",
       "\n",
       "  dataset language                                       tokens_train  \\\n",
       "0    CORE  English  [▁See, king, ▁All, ▁Things, ▁Br, illian, t, ▁\"...   \n",
       "1    CORE  English  [▁Meet, ▁Or, ch, id, ▁du, ▁Bo, is, ▁I, ▁first,...   \n",
       "2    CORE  English  [▁Abstract, ▁Object, ive, :, ▁Report, ing, ▁bi...   \n",
       "\n",
       "                                           token_ids  \n",
       "0  [6872, 6048, 3164, 119175, 13008, 162076, 18, ...  \n",
       "1  [72626, 3347, 206, 532, 115, 2460, 164, 87, 51...  \n",
       "2  [233973, 134549, 5844, 12, 34798, 214, 333, 16...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize the train dataset as well\n",
    "tokens_train = []\n",
    "integers_train = []\n",
    "token_list_train = []\n",
    "\n",
    "for text in tqdm(train_df.text.to_list()):\n",
    "\tencoded_text = tokenizer(text)\n",
    "\t# Take all tokens_train, except the beginning (<s>) and end (</s>) token\n",
    "\tcurrent_tokens_train = tokenizer.convert_ids_to_tokens(encoded_text.input_ids)[1:-1]\n",
    "\ttokens_train.append(current_tokens_train)\n",
    "\ttoken_list_train.extend(current_tokens_train)\n",
    "\tintegers_train.append(encoded_text.input_ids[1:-1])\n",
    "\n",
    "train_df[\"tokens_train\"] = tokens_train\n",
    "train_df[\"token_ids\"] = integers_train\n",
    "\n",
    "print(token_list_train[:10])\n",
    "print(len(token_list_train))\n",
    "\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700411"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of tokens, where we take only the first 512 tokens\n",
    "train_tokens_shortened = []\n",
    "\n",
    "for i in train_df[\"tokens_train\"].to_list():\n",
    "\ttrain_tokens_shortened.extend(i[:513])\n",
    "\n",
    "len(train_tokens_shortened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4508"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See how many tokens overlap\n",
    "overlap_counter = 0\n",
    "\n",
    "for token in token_list:\n",
    "\tif token in train_tokens_shortened:\n",
    "\t\toverlap_counter += 1\n",
    "\n",
    "overlap_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1483529140750979"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Out of all tokens, how many overlap?\n",
    "overlap_counter/len(token_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Croatian, 82% of tokens overlap with train_df, for Macedonian 15%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the tokenized version\n",
    "train_df.to_json(\"datasets/tokenized_datasets/X-GENRE-train-tokenized.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crosslingual_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
