{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tajak/Crosslingual-Genre-Bias-Analysis/crosslingual_venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Define the gpu  on the gpu machine\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=6\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate token distribution - vector of values per tokens (how many times does each token occur) - create a dictionary with all tokens from train set and specific test set, iterate through the tokens and count how many times each ocurrs. Calculate cosine similarity.\n",
    "\n",
    "Do this on label level as well to see whether this explains good performance on some of the labels for Maltese."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize and count tokens for train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for tokenization (it is now already done):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>dataset</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seeking All Things Brilliant \"I want people to...</td>\n",
       "      <td>Other</td>\n",
       "      <td>CORE</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Meet Orchid du Bois I first met Hayley Mowday ...</td>\n",
       "      <td>Other</td>\n",
       "      <td>CORE</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text labels dataset language\n",
       "0  Seeking All Things Brilliant \"I want people to...  Other    CORE  English\n",
       "1  Meet Orchid du Bois I first met Hayley Mowday ...  Other    CORE  English"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1772 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1810 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 1772/1772 [00:09<00:00, 189.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "699465\n"
     ]
    }
   ],
   "source": [
    "# Import the train dataset\n",
    "train = load_dataset(\"TajaKuzman/X-GENRE-multilingual-text-genre-dataset\", \"train\")\n",
    "\n",
    "# To open as Pandas DataFrame:\n",
    "train_df = pd.DataFrame(train[\"train\"])\n",
    "\n",
    "display(train_df.head(2))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "\n",
    "# Tokenize the train dataset\n",
    "tokens_train = []\n",
    "integers_train = []\n",
    "token_list_train = []\n",
    "\n",
    "for text in tqdm(train_df.text.to_list()):\n",
    "\tencoded_text = tokenizer(text)\n",
    "\t# Take all tokens_train, except the beginning (<s>) and end (</s>) token\n",
    "\tcurrent_tokens_train = tokenizer.convert_ids_to_tokens(encoded_text.input_ids)[1:-1]\n",
    "\ttokens_train.append(current_tokens_train)\n",
    "\ttoken_list_train.extend(current_tokens_train)\n",
    "\tintegers_train.append(encoded_text.input_ids[1:-1])\n",
    "\n",
    "train_df[\"tokens_train\"] = tokens_train\n",
    "train_df[\"token_ids\"] = integers_train\n",
    "\n",
    "#print(token_list_train[:10])\n",
    "#print(len(token_list_train))\n",
    "\n",
    "# Create a list of tokens, where we take only the first 512 tokens\n",
    "train_tokens_shortened = []\n",
    "\n",
    "for i in train_df[\"tokens_train\"].to_list():\n",
    "\ttrain_tokens_shortened.extend(i[:512])\n",
    "\n",
    "print(len(train_tokens_shortened))\n",
    "\n",
    "train_df.head(3)\n",
    "\n",
    "# Save the tokenized version\n",
    "train_df.to_json(\"datasets/tokenized_datasets/X-GENRE-train-tokenized.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to count tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>dataset</th>\n",
       "      <th>language</th>\n",
       "      <th>tokens_train</th>\n",
       "      <th>token_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seeking All Things Brilliant \"I want people to...</td>\n",
       "      <td>Other</td>\n",
       "      <td>CORE</td>\n",
       "      <td>English</td>\n",
       "      <td>[▁See, king, ▁All, ▁Things, ▁Br, illian, t, ▁\"...</td>\n",
       "      <td>[6872, 6048, 3164, 119175, 13008, 162076, 18, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Meet Orchid du Bois I first met Hayley Mowday ...</td>\n",
       "      <td>Other</td>\n",
       "      <td>CORE</td>\n",
       "      <td>English</td>\n",
       "      <td>[▁Meet, ▁Or, ch, id, ▁du, ▁Bo, is, ▁I, ▁first,...</td>\n",
       "      <td>[72626, 3347, 206, 532, 115, 2460, 164, 87, 51...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text labels dataset language  \\\n",
       "0  Seeking All Things Brilliant \"I want people to...  Other    CORE  English   \n",
       "1  Meet Orchid du Bois I first met Hayley Mowday ...  Other    CORE  English   \n",
       "\n",
       "                                        tokens_train  \\\n",
       "0  [▁See, king, ▁All, ▁Things, ▁Br, illian, t, ▁\"...   \n",
       "1  [▁Meet, ▁Or, ch, id, ▁du, ▁Bo, is, ▁I, ▁first,...   \n",
       "\n",
       "                                           token_ids  \n",
       "0  [6872, 6048, 3164, 119175, 13008, 162076, 18, ...  \n",
       "1  [72626, 3347, 206, 532, 115, 2460, 164, 87, 51...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the tokenized df\n",
    "train_df = pd.read_json(\"datasets/tokenized_datasets/X-GENRE-train-tokenized.json\")\n",
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "699465\n",
      "[('!', 430), ('!!', 23), ('!!!', 14), ('!!!!', 6), ('!!!!!', 1), ('!!!!!!', 1), ('!!!!!!!', 1), ('!\"', 14), ('!)', 10), ('!),', 1), ('!).', 2), ('\"', 528), ('\")', 7), ('\"),', 6), ('\").', 7), ('\",', 56), ('\".', 83), ('\"...', 3), ('\";', 3), ('\"?', 6), ('#', 4), ('$', 8), ('%', 4), ('%)', 1), ('&', 46), (\"'\", 4517), ('(', 31), ('(1', 1), (')', 788), ('),', 242), (').', 297), ('):', 13), (');', 5), ('*', 19), ('**', 2), ('****', 1), ('+', 15), ('+5', 1), (',', 23447), (',«', 12), ('-', 2803), ('---', 3), ('------', 5), ('----------------', 41), ('-0', 3), ('-01', 1), ('-02', 2), ('-02-', 2), ('-03-', 4), ('-06', 1), ('-06-', 3), ('-09-', 1), ('-1', 15), ('-1)', 3), ('-10', 2), ('-10-', 1), ('-11', 6), ('-11-', 1), ('-12', 8), ('-13', 6), ('-14', 3), ('-15', 7), ('-16', 9), ('-17', 3), ('-18', 9), ('-19', 5), ('-2', 10), ('-20', 3), ('-2000', 3), ('-2005', 1), ('-2007', 8), ('-2009', 1), ('-2010', 1), ('-2011', 1), ('-2012', 1), ('-2014', 1), ('-2020', 1), ('-21', 4), ('-22', 3), ('-23', 2), ('-24', 3), ('-25', 1), ('-26', 2), ('-27', 3), ('-28', 1), ('-29', 1), ('-3', 10), ('-30', 5), ('-300', 1), ('-31', 2), ('-33', 1), ('-34', 1), ('-35', 1), ('-36', 1), ('-4', 5), ('-40', 1), ('-45', 3), ('-5', 4), ('-50', 1), ('-52', 1)]\n",
      "27025\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary that counts all the token occurrences\n",
    "\n",
    "# Create a list of tokens, where we take only the first 512 tokens\n",
    "train_tokens_shortened = []\n",
    "\n",
    "for i in train_df[\"tokens_train\"].to_list():\n",
    "\ttrain_tokens_shortened.extend(i[:512])\n",
    "\n",
    "print(len(train_tokens_shortened))\n",
    "\n",
    "# Create a dictionary which counts the occurrences of the words\n",
    "\n",
    "word_dict_train = Counter(train_tokens_shortened)\n",
    "\n",
    "# Sort the dictionary alphabetically based on keys\n",
    "word_dict_train = dict(sorted(word_dict_train.items()))\n",
    "\n",
    "print(list(word_dict_train.items())[:100])\n",
    "print(len(word_dict_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train dataset has 699.465 tokens and 27.025 unique words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 23447),\n",
       " ('.', 21407),\n",
       " ('▁', 19553),\n",
       " ('▁the', 18860),\n",
       " ('s', 14184),\n",
       " ('▁to', 10762),\n",
       " ('▁of', 9912),\n",
       " ('▁and', 9752),\n",
       " ('▁in', 9140),\n",
       " ('▁a', 8341)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the most frequent tokens:\n",
    "\n",
    "# Sort the dictionary by values (word counts) in descending order\n",
    "sorted(word_dict_train.items(), key=lambda x: x[1], reverse=True)[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dictionary of tokens\n",
    "with open(\"datasets/tokenized_datasets/X-GENRE-train-token-count.json\", \"w\") as train_count_file:\n",
    "\tjson.dump(word_dict_train, train_count_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize and count tokens for test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code with which I tokenized the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mt', 'el', 'tr', 'sq', 'is', 'uk', 'ca', 'mk', 'hr', 'sl'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the final dataset with test sets\n",
    "with open(\"manual-annotations/multilingual-genre-annotated-test-set.json\") as main_file:\n",
    "\tmain_dict = json.load(main_file)\n",
    "\n",
    "main_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an array of token overlap\n",
    "token_overlap_results = {}\n",
    "\n",
    "# Loop through the datasets and calculate token overlap\n",
    "for lang in list(main_dict.keys()):\n",
    "\tdf = pd.DataFrame(main_dict[lang][\"dataset\"])\n",
    "\n",
    "\ttokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "\n",
    "\ttokens = []\n",
    "\tintegers = []\n",
    "\ttoken_list = []\n",
    "\n",
    "\tprint(\"Tokenizing text.\")\n",
    "\n",
    "\tfor text in tqdm(df.text.to_list()):\n",
    "\t\tencoded_text = tokenizer(text)\n",
    "\t\t# Take all tokens, except the beginning (<s>) and end (</s>) token\n",
    "\t\tcurrent_tokens = tokenizer.convert_ids_to_tokens(encoded_text.input_ids)[1:-1]\n",
    "\t\t# Shorten the list to 512, as tokens after that were not observed by the classifier\n",
    "\t\tcurrent_tokens = current_tokens[:512]\n",
    "\t\ttokens.append(current_tokens)\n",
    "\t\ttoken_list.extend(current_tokens)\n",
    "\t\tintegers.append(encoded_text.input_ids[1:-1][:512])\n",
    "\n",
    "\tdf[\"tokens\"] = tokens\n",
    "\tdf[\"token_ids\"] = integers\n",
    "\n",
    "\tprint(token_list[:10])\n",
    "\tprint(\"All tokens:\")\n",
    "\tprint(len(token_list))\n",
    "\n",
    "\t# See how many tokens overlap\n",
    "\toverlap_counter = 0\n",
    "\n",
    "\tprint(\"Calculating overlap.\")\n",
    "\n",
    "\t# Save tokens that overlap for further inspection\n",
    "\toverlap_token_list = []\n",
    "\n",
    "\t#overlap_counter = sum(1 for element in token_list if element in train_tokens_shortened)\n",
    "\tfor token in tqdm(token_list):\n",
    "\t\tif token in train_tokens_shortened:\n",
    "\t\t\toverlap_counter += 1\n",
    "\t\t\toverlap_token_list.append(token)\n",
    "\n",
    "\t# Out of all tokens, how many overlap?\n",
    "\toverlap_per = overlap_counter/len(token_list)\n",
    "\n",
    "\tprint(f\"Number of tokens that overlap: {overlap_counter}\")\n",
    "\tprint(f\"Percentage of overlap: {overlap_per}\")\n",
    "\n",
    "\t# Update the dataset in the dictionary\n",
    "\tmain_dict[lang][\"dataset\"] = df.to_dict()\n",
    "\n",
    "\t# Add the list of all tokens to the dictionary\n",
    "\tmain_dict[lang][\"token_overlap\"] = {\"overlap_percentage\":overlap_per, \"token_list\": token_list, \"overlap_token_list\":overlap_token_list}\n",
    "\n",
    "\t# Add to the results\n",
    "\ttoken_overlap_results[lang] = {\"percentage\": overlap_per, \"overlap_list\": overlap_token_list}\n",
    "\n",
    "\t# Convert tokens back to words\n",
    "\t#print(tokenizer.convert_tokens_to_string(tokens))\n",
    "\n",
    "# Inspect the results\n",
    "overlap_df = pd.DataFrame(token_overlap_results)\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>percentage</th>\n",
       "      <th>overlap_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mt</th>\n",
       "      <td>0.817085</td>\n",
       "      <td>[▁Angel, o, ▁Che, t, ,, ▁se, ▁j, kun, d, u, ▁p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>el</th>\n",
       "      <td>0.161428</td>\n",
       "      <td>[asi, asi, ,, ,, ▁Re, ception, ., ▁driver, ▁es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr</th>\n",
       "      <td>0.521502</td>\n",
       "      <td>[▁A, L, ▁Der, s, i, ▁ve, ▁Beli, r, leme, ▁S, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sq</th>\n",
       "      <td>0.605775</td>\n",
       "      <td>[▁Blog, ▁“, U, ▁kam, ▁me, jet, .”, ▁Jer, ▁31, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>0.517575</td>\n",
       "      <td>[▁[, is, ], ▁er, fi, ▁reg, ▁sett, ar, lag, sin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uk</th>\n",
       "      <td>0.156675</td>\n",
       "      <td>[., ,, ,, ?, ▁-, ., ?, ▁-, ', ., ,, ., ▁, ▁(, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca</th>\n",
       "      <td>0.744881</td>\n",
       "      <td>[▁P, à, gine, s, ▁En, nada, ▁Porto, ▁uns, ▁die...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mk</th>\n",
       "      <td>0.145989</td>\n",
       "      <td>[,, ▁T, CL, ,, ▁T, CL, :, ▁Alca, tel, ▁Mobile,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hr</th>\n",
       "      <td>0.821517</td>\n",
       "      <td>[▁O, ▁proizvod, u, ▁Color, ▁Trans, ,, ▁za, ▁pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sl</th>\n",
       "      <td>0.974289</td>\n",
       "      <td>[▁Kita, jsko, ▁mesto, ▁duhov, ▁V, ▁Notranj, i,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   percentage                                       overlap_list\n",
       "mt   0.817085  [▁Angel, o, ▁Che, t, ,, ▁se, ▁j, kun, d, u, ▁p...\n",
       "el   0.161428  [asi, asi, ,, ,, ▁Re, ception, ., ▁driver, ▁es...\n",
       "tr   0.521502  [▁A, L, ▁Der, s, i, ▁ve, ▁Beli, r, leme, ▁S, h...\n",
       "sq   0.605775  [▁Blog, ▁“, U, ▁kam, ▁me, jet, .”, ▁Jer, ▁31, ...\n",
       "is   0.517575  [▁[, is, ], ▁er, fi, ▁reg, ▁sett, ar, lag, sin...\n",
       "uk   0.156675  [., ,, ,, ?, ▁-, ., ?, ▁-, ', ., ,, ., ▁, ▁(, ...\n",
       "ca   0.744881  [▁P, à, gine, s, ▁En, nada, ▁Porto, ▁uns, ▁die...\n",
       "mk   0.145989  [,, ▁T, CL, ,, ▁T, CL, :, ▁Alca, tel, ▁Mobile,...\n",
       "hr   0.821517  [▁O, ▁proizvod, u, ▁Color, ▁Trans, ,, ▁za, ▁pa...\n",
       "sl   0.974289  [▁Kita, jsko, ▁mesto, ▁duhov, ▁V, ▁Notranj, i,..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlap_df = pd.DataFrame(token_overlap_results).transpose()\n",
    "overlap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁Angel\n"
     ]
    }
   ],
   "source": [
    "for token in overlap_df[\"overlap_list\"].to_list()[0][:2]:\n",
    "\tif len(token) > 1:\n",
    "\t\tnon_short_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>percentage</th>\n",
       "      <th>overlap_list</th>\n",
       "      <th>non_short</th>\n",
       "      <th>non_short_per</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mt</th>\n",
       "      <td>0.817085</td>\n",
       "      <td>[▁Angel, o, ▁Che, t, ,, ▁se, ▁j, kun, d, u, ▁p...</td>\n",
       "      <td>23083</td>\n",
       "      <td>0.723628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>el</th>\n",
       "      <td>0.161428</td>\n",
       "      <td>[asi, asi, ,, ,, ▁Re, ception, ., ▁driver, ▁es...</td>\n",
       "      <td>1883</td>\n",
       "      <td>0.373389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr</th>\n",
       "      <td>0.521502</td>\n",
       "      <td>[▁A, L, ▁Der, s, i, ▁ve, ▁Beli, r, leme, ▁S, h...</td>\n",
       "      <td>11141</td>\n",
       "      <td>0.722269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sq</th>\n",
       "      <td>0.605775</td>\n",
       "      <td>[▁Blog, ▁“, U, ▁kam, ▁me, jet, .”, ▁Jer, ▁31, ...</td>\n",
       "      <td>12459</td>\n",
       "      <td>0.768315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>0.517575</td>\n",
       "      <td>[▁[, is, ], ▁er, fi, ▁reg, ▁sett, ar, lag, sin...</td>\n",
       "      <td>10915</td>\n",
       "      <td>0.711399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uk</th>\n",
       "      <td>0.156675</td>\n",
       "      <td>[., ,, ,, ?, ▁-, ., ?, ▁-, ', ., ,, ., ▁, ▁(, ...</td>\n",
       "      <td>1258</td>\n",
       "      <td>0.253476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca</th>\n",
       "      <td>0.744881</td>\n",
       "      <td>[▁P, à, gine, s, ▁En, nada, ▁Porto, ▁uns, ▁die...</td>\n",
       "      <td>15657</td>\n",
       "      <td>0.763123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mk</th>\n",
       "      <td>0.145989</td>\n",
       "      <td>[,, ▁T, CL, ,, ▁T, CL, :, ▁Alca, tel, ▁Mobile,...</td>\n",
       "      <td>1270</td>\n",
       "      <td>0.314746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hr</th>\n",
       "      <td>0.821517</td>\n",
       "      <td>[▁O, ▁proizvod, u, ▁Color, ▁Trans, ,, ▁za, ▁pa...</td>\n",
       "      <td>17678</td>\n",
       "      <td>0.810620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sl</th>\n",
       "      <td>0.974289</td>\n",
       "      <td>[▁Kita, jsko, ▁mesto, ▁duhov, ▁V, ▁Notranj, i,...</td>\n",
       "      <td>21567</td>\n",
       "      <td>0.841935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   percentage                                       overlap_list  non_short  \\\n",
       "mt   0.817085  [▁Angel, o, ▁Che, t, ,, ▁se, ▁j, kun, d, u, ▁p...      23083   \n",
       "el   0.161428  [asi, asi, ,, ,, ▁Re, ception, ., ▁driver, ▁es...       1883   \n",
       "tr   0.521502  [▁A, L, ▁Der, s, i, ▁ve, ▁Beli, r, leme, ▁S, h...      11141   \n",
       "sq   0.605775  [▁Blog, ▁“, U, ▁kam, ▁me, jet, .”, ▁Jer, ▁31, ...      12459   \n",
       "is   0.517575  [▁[, is, ], ▁er, fi, ▁reg, ▁sett, ar, lag, sin...      10915   \n",
       "uk   0.156675  [., ,, ,, ?, ▁-, ., ?, ▁-, ', ., ,, ., ▁, ▁(, ...       1258   \n",
       "ca   0.744881  [▁P, à, gine, s, ▁En, nada, ▁Porto, ▁uns, ▁die...      15657   \n",
       "mk   0.145989  [,, ▁T, CL, ,, ▁T, CL, :, ▁Alca, tel, ▁Mobile,...       1270   \n",
       "hr   0.821517  [▁O, ▁proizvod, u, ▁Color, ▁Trans, ,, ▁za, ▁pa...      17678   \n",
       "sl   0.974289  [▁Kita, jsko, ▁mesto, ▁duhov, ▁V, ▁Notranj, i,...      21567   \n",
       "\n",
       "    non_short_per  \n",
       "mt       0.723628  \n",
       "el       0.373389  \n",
       "tr       0.722269  \n",
       "sq       0.768315  \n",
       "is       0.711399  \n",
       "uk       0.253476  \n",
       "ca       0.763123  \n",
       "mk       0.314746  \n",
       "hr       0.810620  \n",
       "sl       0.841935  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect how many tokens are one character long\n",
    "\n",
    "counters = []\n",
    "pers = []\n",
    "\n",
    "for token_list_el in overlap_df[\"overlap_list\"].to_list():\n",
    "\tnon_short_counter = 0\n",
    "\tfor token in token_list_el:\n",
    "\t\tif len(token) > 1:\n",
    "\t\t\tnon_short_counter += 1\n",
    "\t\n",
    "\tcounters.append(non_short_counter)\n",
    "\tpers.append(non_short_counter/len(token_list_el))\n",
    "\n",
    "# Add to df\n",
    "overlap_df[\"non_short\"] = counters\n",
    "\n",
    "# Calculate the percentage of overlap tokens that have more than 1 character\n",
    "overlap_df[\"non_short_per\"] = pers\n",
    "\n",
    "overlap_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the extended json dict\n",
    "with open(\"manual-annotations/multilingual-genre-annotated-test-set.json\", \"w\") as file:\n",
    "\tjson.dump(main_dict, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add token counts information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mt', 'el', 'tr', 'sq', 'is', 'uk', 'ca', 'mk', 'hr', 'sl'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the final dataset with test sets\n",
    "with open(\"manual-annotations/multilingual-genre-annotated-test-set.json\") as main_file:\n",
    "\tmain_dict = json.load(main_file)\n",
    "\n",
    "main_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating token dict for mt\n",
      "No of tokens: 39040\n",
      "[('!', 9), ('\"', 34), ('\",', 11), ('\".', 6), ('#', 20), (\"'\", 462), ('(', 3), ('(1)', 4), ('(2)', 4), ('(3)', 4), (')', 50), ('),', 15), (').', 15), (');', 1), (',', 884), ('-', 2119), ('-0', 1), ('-1', 1), ('-11', 1), ('-12-', 2), ('-16', 5), ('-17', 1), ('-18', 2), ('-19', 1), ('-2', 5), ('-20', 1), ('-200', 1), ('-2000', 1), ('-2007', 1), ('-2009', 1), ('-2014', 1), ('-2015', 1), ('-2016', 2), ('-2017', 2), ('-21', 1), ('-22', 1), ('-23', 1), ('-24', 2), ('-28', 1), ('-30', 4), ('-35', 1), ('-4', 1), ('-5', 1), ('-500', 1), ('-6', 1), ('-7', 1), ('-90', 2), ('.', 724), ('.\"', 5), ('...', 1), ('.”', 3), ('/', 11), ('/08', 3), ('/13', 1), ('/14', 3), ('/19', 4), ('/24', 2), ('/3', 6), ('/4', 2), ('/5', 2), ('/7', 2), ('0.7', 1), ('00', 1), ('016', 1), ('02', 2), ('04', 2), ('05', 1), ('050', 1), ('09.', 2), ('1', 5), ('100', 1), ('112', 1), ('12', 2), ('135', 2), ('14', 1), ('152', 1), ('164', 1), ('19', 5), ('1962', 1), ('1998', 1), ('2', 2), ('2)', 1), ('2.', 1), ('2.5', 1), ('2/', 5), ('20', 1), ('200', 1), ('2003', 1), ('2006', 1), ('2008', 1), ('2009', 1), ('2014', 1), ('2016', 1), ('2019', 3), ('22', 1), ('23', 1), ('25', 2), ('26', 1), ('29', 2), ('3', 2)]\n",
      "No of unique tokens: 4787\n",
      "Creating token dict for el\n",
      "No of tokens: 31240\n",
      "[('!', 23), ('!!', 2), ('!!!', 5), ('!!!!!!', 1), ('\"', 55), ('\"),', 2), ('\",', 17), ('\".', 21), ('\"?', 1), ('&', 9), (\"'\", 39), ('(', 8), ('(1)', 1), ('(2)', 1), (')', 60), ('),', 15), (').', 12), ('):', 3), ('+', 2), ('+4', 1), (',', 782), ('-', 45), ('-0', 2), ('-00', 4), ('-1', 1), ('-10', 1), ('-14', 1), ('-17', 1), ('-19', 1), ('-2014', 1), ('-25', 1), ('-34', 1), ('-4', 1), ('-50', 1), ('-52', 1), ('.', 801), ('.\"', 1), ('...', 30), ('.....', 1), ('......', 3), ('.........', 1), ('.000', 2), ('.[1]', 1), ('/', 24), ('/02', 1), ('/05/20', 1), ('/07/', 2), ('/12', 4), ('/20', 1), ('/2005', 1), ('/2016', 3), ('/2017', 3), ('/5', 2), ('/8', 1), ('00', 2), ('00€', 3), ('01', 12), ('03', 1), ('05', 1), ('070', 1), ('1', 7), ('1/10', 1), ('10', 3), ('11', 1), ('12', 1), ('149', 1), ('16', 1), ('18', 1), ('185', 1), ('19', 1), ('1998', 1), ('2', 17), ('2%', 1), ('2)', 1), ('2,6', 1), ('2.', 1), ('20', 3), ('2004', 1), ('2013', 1), ('2015', 2), ('2017', 1), ('2019', 1), ('2022', 2), ('22', 1), ('23', 2), ('25', 1), ('28', 2), ('29', 5), ('2]', 1), ('3', 10), ('3-', 1), ('310', 1), ('32', 3), ('35', 1), ('36', 1), ('361', 1), ('39)', 1), ('3]', 1), ('4', 1), ('4-', 1)]\n",
      "No of unique tokens: 4751\n",
      "Creating token dict for tr\n",
      "No of tokens: 29578\n",
      "[('!', 21), ('!!', 2), ('!!!', 1), ('!\"', 2), ('\"', 69), ('\",', 3), ('\"?', 1), ('#', 1), ('%', 1), ('&', 1), (\"'\", 244), (\"''\", 7), ('(', 6), (')', 83), (')))', 2), ('),', 1), (').', 5), ('):', 2), ('*', 3), ('+', 1), ('+00:00', 3), (',', 806), ('-', 64), ('----------------', 5), ('-0', 2), ('-02-', 3), ('-1)', 1), ('-11', 1), ('-11-', 1), ('-14', 1), ('-19', 5), ('-200', 4), ('-21', 1), ('-3', 1), ('-60', 1), ('-7', 1), ('-70', 1), ('.', 995), ('.\"', 5), (\".''\", 1), ('...', 31), ('...\"', 1), ('...(', 2), ('......', 1), ('.12.2018', 1), ('/', 37), ('/02/', 1), ('/09/', 1), ('/1', 1), ('/12/', 2), ('/12/2018', 1), ('/14', 2), ('/6', 3), ('02', 2), ('04', 3), ('04)', 1), ('05', 2), ('06', 2), ('07', 2), ('09', 6), ('1', 3), ('1.2', 1), ('10', 8), ('100', 2), ('101', 1), ('11', 1), ('110', 1), ('111', 2), ('12', 1), ('12)', 1), ('125', 1), ('13', 2), ('130', 1), ('14', 1), ('15', 2), ('16', 5), ('17', 1), ('1800', 1), ('19', 2), ('1980', 1), ('1998', 1), ('2', 2), ('2)', 2), ('2-', 1), ('2.8', 1), ('20', 3), ('2003', 2), ('2004', 3), ('2021', 5), ('22', 1), ('23', 2), ('232', 1), ('25)', 1), ('29', 2), ('3', 8), ('3)', 2), ('3,5', 1), ('30', 1), ('31', 2), ('367', 1)]\n",
      "No of unique tokens: 6272\n",
      "Creating token dict for sq\n",
      "No of tokens: 26769\n",
      "[('!', 29), ('!!', 3), ('!!!', 4), ('!!!!!', 1), ('!”', 3), ('\"', 7), ('\"),', 1), ('\",', 3), ('\".', 1), ('%)', 1), ('&', 1), (\"'\", 38), ('(', 2), (')', 35), ('),', 10), (').', 6), ('):', 3), ('+', 3), ('+1', 1), (',', 807), ('-', 60), ('---', 1), ('------', 1), ('-12', 1), ('-13', 1), ('-19', 1), ('-20', 1), ('-26', 1), ('.', 641), ('...', 31), ('...!!', 1), ('.....', 3), ('......', 4), ('.......', 1), ('...............', 1), ('................', 7), ('.03.2015', 1), ('.05.', 2), ('.10.', 1), ('.11.20', 2), ('.12.', 2), ('.3.', 1), ('.4.', 1), ('.8.', 1), ('.”', 4), ('/', 24), ('/06', 1), ('/1', 3), ('/11', 2), ('/11/', 2), ('/2', 1), ('/2007', 1), ('/2008', 1), ('/2013', 1), ('/2015', 1), ('/3', 1), ('0.4', 1), ('04.', 1), ('06.', 1), ('07', 1), ('1', 4), ('1-6', 1), ('1/4', 1), ('10', 1), ('11', 4), ('12', 1), ('13', 1), ('166', 1), ('17', 2), ('1950', 1), ('1960', 1), ('1961', 1), ('1974', 2), ('1976', 1), ('1979', 1), ('1987', 1), ('1989', 2), ('1992', 1), ('1994', 1), ('2', 5), ('20', 1), ('2005', 1), ('2007', 1), ('2008', 1), ('2020', 2), ('2021', 1), ('21', 2), ('23', 1), ('25', 1), ('3', 1), ('3,4', 1), ('3.3', 1), ('30', 1), ('305', 1), ('31', 2), ('32', 1), ('355', 1), ('357', 1), ('367', 1), ('4%', 1)]\n",
      "No of unique tokens: 4891\n",
      "Creating token dict for is\n",
      "No of tokens: 29644\n",
      "[('!', 15), ('!!!', 2), ('!!!!', 1), ('!\"', 1), ('\"', 25), ('\",', 1), ('\".', 2), ('&', 1), (\"'\", 4), ('(', 1), (')', 22), ('),', 6), (').', 9), ('*', 2), ('**', 1), (',', 600), (',7%', 1), ('-', 79), ('-1', 1), ('-1)', 1), ('-16', 1), ('-18', 1), ('-2', 2), ('-2005', 1), ('-2011', 1), ('-2016', 1), ('-21', 1), ('-22', 1), ('-3', 2), ('-4', 1), ('-5', 1), ('.', 1017), ('.\"', 14), ('...', 21), ('...\"', 1), ('.....', 1), ('.12.', 2), ('/', 19), ('/2018', 1), ('0', 1), ('00000', 1), ('001', 1), ('006', 2), ('01', 2), ('03', 2), ('030', 1), ('04', 1), ('04.', 1), ('05', 1), ('08.', 1), ('09.', 3), ('1', 2), ('1%', 1), ('1,5%', 1), ('1-4', 1), ('10', 2), ('100', 1), ('101', 1), ('105', 1), ('11', 2), ('12', 1), ('12)', 1), ('120', 1), ('123', 1), ('124', 1), ('13', 2), ('14', 2), ('15', 2), ('16', 2), ('17', 3), ('1998', 1), ('2', 6), ('2%', 2), ('2-3', 1), ('200', 2), ('2003', 1), ('2009', 1), ('2019', 1), ('21)', 1), ('22', 2), ('22)', 1), ('25', 1), ('28', 1), ('280', 1), ('290', 1), ('2°', 1), ('3', 2), ('30', 1), ('342', 1), ('35', 1), ('38', 1), ('3°', 1), ('4', 8), ('4%', 3), ('4,6', 1), ('4/', 1), ('40', 1), ('433', 1), ('45', 1), ('5', 5)]\n",
      "No of unique tokens: 4615\n",
      "Creating token dict for uk\n",
      "No of tokens: 31677\n",
      "[('!', 41), ('!!', 1), ('!!!', 6), ('!\"', 2), ('!).', 1), ('!»', 4), ('\"', 35), ('\")', 1), ('\").', 1), ('\",', 5), ('\".', 5), ('\"?', 1), ('$', 3), ('%', 1), ('&', 11), (\"'\", 53), ('(', 5), (')', 63), (')))', 8), ('),', 10), (').', 27), ('):', 1), (');', 1), ('*', 4), ('+', 10), (',', 1352), ('-', 132), ('------', 3), ('-1', 1), ('-100', 1), ('-16', 3), ('-18', 1), ('-21', 1), ('-5', 1), ('.', 1031), ('.\"', 2), ('...', 46), ('...\"', 1), ('.....', 1), ('.1.1', 1), ('.11.20', 1), ('.3.', 2), ('.4.', 1), ('.5.', 1), ('/', 13), ('/08', 1), ('/19', 1), ('/20', 1), ('/2006', 8), ('0000', 1), ('004', 1), ('01', 1), ('010', 1), ('02.', 2), ('03.', 1), ('07.', 1), ('09.', 1), ('1', 4), ('1.2', 1), ('10', 4), ('10)', 1), ('102', 1), ('105', 1), ('1080', 1), ('11', 1), ('12', 1), ('132', 1), ('140', 1), ('150', 1), ('154', 1), ('156', 1), ('157', 1), ('168', 1), ('17)', 1), ('19', 1), ('1991', 1), ('1996', 1), ('2', 6), ('2-1', 1), ('2.', 1), ('2.5', 1), ('2006', 1), ('2008', 1), ('2013', 1), ('2022', 1), ('21', 1), ('23', 1), ('24', 1), ('25', 3), ('28', 1), ('297', 1), ('3', 2), ('3-', 1), ('3.7', 1), ('30', 2), ('31)', 1), ('332', 1), ('36', 1), ('360', 1), ('385', 1)]\n",
      "No of unique tokens: 6507\n",
      "Creating token dict for ca\n",
      "No of tokens: 27544\n",
      "[('!', 60), ('!!', 7), ('!!!', 8), ('!!!!!!', 1), ('!!!!!!!', 1), ('!),', 1), ('!).', 3), ('!”', 8), ('\"', 7), ('\",', 1), ('&', 3), (\"'\", 360), ('(', 2), (')', 50), ('),', 15), (').', 19), (');', 1), ('+', 1), (',', 1080), ('-', 133), ('-19', 5), ('-20', 2), ('-3', 1), ('-5', 1), ('.', 675), ('...', 64), ('...)', 1), ('...).', 1), ('.....', 5), ('......', 4), ('.........', 2), ('.............', 1), ('...”', 1), ('.[1]', 1), ('.«', 1), ('/', 42), ('/03/', 2), ('/04/', 2), ('/05/20', 1), ('/07', 1), ('/08', 2), ('/09/', 2), ('/12/', 1), ('/2000', 1), ('/2002', 3), ('/2003', 1), ('/2004', 1), ('/2005', 1), ('/2008', 1), ('/2009', 1), ('/2010', 2), ('/2015', 2), ('/2016', 1), ('/6', 1), ('00', 1), ('000.000', 2), ('0000', 1), ('01', 1), ('020', 2), ('03.', 1), ('07', 1), ('070', 1), ('08)', 1), ('1', 6), ('1.1', 1), ('1.2', 1), ('1.4', 2), ('1.5', 1), ('1.6', 1), ('1/10', 1), ('10', 3), ('13', 1), ('137', 1), ('164', 2), ('17', 1), ('173', 2), ('18', 1), ('1945', 2), ('1968', 2), ('1981', 1), ('1983', 1), ('1991', 2), ('1993', 1), ('2', 5), ('2011', 1), ('2015', 2), ('2016', 1), ('2017', 1), ('2018', 1), ('2021', 1), ('2022', 13), ('22', 2), ('23', 2), ('25)', 2), ('250', 1), ('26', 1), ('265', 1), ('278', 1), ('29', 3), ('297', 1)]\n",
      "No of unique tokens: 5314\n",
      "Creating token dict for mk\n",
      "No of tokens: 27639\n",
      "[('!', 22), ('!!!', 1), ('!\"', 3), ('\"', 53), ('\",', 15), ('\".', 5), ('%', 2), ('&', 1), (\"'\", 4), ('(', 9), (')', 32), ('),', 6), (').', 9), (');', 2), ('*', 5), ('+', 1), ('++', 1), ('+3', 1), (',', 1021), ('-', 47), ('-0', 8), ('-24', 1), ('-30', 1), ('-31', 1), ('-8', 1), ('->', 9), ('.', 738), ('.\"', 1), ('...', 34), ('...\"', 2), ('.000', 1), ('.000,00', 4), ('.04.20', 4), ('.09.2015', 1), ('.10.', 1), ('.11.', 1), ('.12.', 1), ('.4.', 1), ('/', 38), ('/01/', 1), ('/05', 1), ('/06', 1), ('/07', 1), ('/08', 1), ('/10', 2), ('/11', 1), ('/13', 2), ('/14', 3), ('/15', 3), ('/16', 2), ('/18', 2), ('/2001', 2), ('/2003', 1), ('/2005', 1), ('/2011', 1), ('01', 1), ('02', 1), ('02.', 1), ('03', 2), ('04', 1), ('05', 1), ('06.', 1), ('1', 3), ('1%', 1), ('10', 2), ('13', 2), ('17', 1), ('18', 3), ('190', 1), ('1974', 1), ('1994', 2), ('2', 3), ('2002', 1), ('2009', 2), ('2010', 1), ('2012', 1), ('2014', 1), ('2018', 1), ('2020', 3), ('2022', 1), ('210', 1), ('229', 1), ('23', 1), ('240', 1), ('25', 1), ('26', 1), ('278', 2), ('3', 4), ('37', 1), ('38', 1), ('39', 1), ('394', 3), ('395', 2), ('3⁄4', 1), ('4', 2), ('4%', 1), ('4,000', 2), ('4,6', 1), ('40', 1), ('46', 1)]\n",
      "No of unique tokens: 5468\n",
      "Creating token dict for hr\n",
      "No of tokens: 26546\n",
      "[('!', 33), ('!!', 1), ('!!!', 3), ('!!!!!!!!!!!!', 1), ('!”', 3), ('\"', 16), ('\",', 10), ('\".', 4), ('#', 1), ('&', 2), (\"'\", 15), (\"''\", 2), ('(', 1), (')', 52), ('),', 9), (').', 19), ('):', 1), ('*', 1), (',', 878), ('-', 82), ('-17', 2), ('-19', 6), ('-2', 4), ('-2000', 1), ('-21', 1), ('-31', 9), ('-5', 1), ('-8', 3), ('.', 766), ('.\"', 3), ('...', 28), ('.....', 2), ('.........', 2), ('.05.', 2), ('.11.', 2), ('.11.20', 5), ('.12.', 24), ('.4.', 1), ('.”', 3), ('/', 31), ('/1', 2), ('/15', 1), ('/16', 1), ('/3', 2), ('/4', 1), ('/5', 1), ('000', 1), ('0000', 1), ('002', 1), ('003', 1), ('02.', 3), ('03', 1), ('05', 1), ('06', 1), ('07', 1), ('08', 2), ('09.', 1), ('1', 1), ('1,5', 1), ('10', 2), ('100', 1), ('1000', 2), ('11', 2), ('12', 2), ('120', 1), ('13', 1), ('14', 1), ('140', 2), ('15', 4), ('155', 1), ('158', 1), ('16', 4), ('165', 1), ('169', 1), ('17', 2), ('18', 1), ('19', 2), ('19)', 2), ('190', 1), ('1950', 1), ('1959', 1), ('1971', 1), ('1997', 1), ('1]', 1), ('2', 2), ('2,50', 1), ('2-3', 1), ('2.', 1), ('2.0', 1), ('2.3', 1), ('2.5', 1), ('20', 2), ('2002', 1), ('2010', 1), ('2017', 3), ('2019', 27), ('2020', 2), ('230', 2), ('28', 1), ('29', 1)]\n",
      "No of unique tokens: 6222\n",
      "Creating token dict for sl\n",
      "No of tokens: 26292\n",
      "[('!', 30), ('!!', 1), ('!\"', 1), ('!),', 1), ('\"', 11), ('\".', 2), ('\"...', 1), ('&', 8), (\"'\", 3), (\"''\", 1), ('(', 2), ('(1)', 1), (')', 45), (')(', 1), ('),', 21), (').', 23), ('*', 3), ('**', 1), ('*******', 1), ('+', 32), (',', 1154), (',«', 2), ('-', 32), ('---', 1), ('-09-', 2), ('-1', 1), ('-1)', 1), ('-16', 1), ('-19', 1), ('-20', 1), ('-300', 1), ('-6', 1), ('.', 805), ('.\"', 2), ('..!', 1), ('...', 26), ('...).', 2), ('.....', 2), ('...”', 1), ('.03.2015', 5), ('.03.2016', 1), ('.11.', 3), ('.11.20', 1), ('.4.', 5), ('.5.', 1), ('.«', 1), ('.”', 1), ('/', 27), ('/03/', 1), ('/09/', 1), ('/12', 2), ('/2002', 2), ('/2003', 2), ('/2004', 2), ('/2005', 2), ('/2006', 3), ('/2007', 2), ('/2008', 3), ('/2014', 4), ('/2016', 1), ('/2017', 1), ('0', 1), ('0,5', 1), ('0.0', 1), ('01', 1), ('02.', 1), ('1', 3), ('1%', 2), ('1,5', 1), ('1,8', 1), ('1.3', 1), ('13', 1), ('14', 1), ('150', 2), ('18', 1), ('19', 4), ('1993', 2), ('2', 6), ('2%', 2), ('2)', 1), ('2,5', 1), ('2.', 1), ('20', 1), ('2008', 7), ('2010', 2), ('2013', 1), ('2015', 2), ('2016', 2), ('2019', 1), ('2020', 1), ('2021', 1), ('22', 2), ('23', 1), ('25', 3), ('2°', 1), ('3', 2), ('3,4', 1), ('3.4', 1), ('30', 2), ('300', 1)]\n",
      "No of unique tokens: 5763\n",
      "|   tokens |   types |\n",
      "|---------:|--------:|\n",
      "|    39040 |    4787 |\n",
      "|    31240 |    4751 |\n",
      "|    29578 |    6272 |\n",
      "|    26769 |    4891 |\n",
      "|    29644 |    4615 |\n",
      "|    31677 |    6507 |\n",
      "|    27544 |    5314 |\n",
      "|    27639 |    5468 |\n",
      "|    26546 |    6222 |\n",
      "|    26292 |    5763 |\n"
     ]
    }
   ],
   "source": [
    "token_number = {}\n",
    "type_number = {}\n",
    "\n",
    "for lang in list(main_dict.keys()):\n",
    "\tprint(f\"Creating token dict for {lang}\")\n",
    "\tcurrent_token_list = main_dict[lang][\"token_overlap\"][\"token_list\"]\n",
    "\n",
    "\tprint(f\"No of tokens: {len(current_token_list)}\")\n",
    "\n",
    "\t# Create a dictionary which counts the occurrences of the tokens\n",
    "\n",
    "\tword_dict_test = Counter(current_token_list)\n",
    "\n",
    "\t# Sort the dictionary alphabetically based on keys\n",
    "\tword_dict_test = dict(sorted(word_dict_test.items()))\n",
    "\n",
    "\t# Add information on no. of tokens and words to a dict\n",
    "\ttoken_number[lang] = len(current_token_list)\n",
    "\ttype_number[lang] = len(word_dict_test)\n",
    "\n",
    "\tprint(list(word_dict_test.items())[:100])\n",
    "\tprint(f\"No of unique tokens: {len(word_dict_test)}\")\n",
    "\n",
    "\t# Add the count of tokens to the main dictionary\n",
    "\tmain_dict[lang][\"token_overlap\"][\"token_count\"] = word_dict_test\n",
    "\n",
    "# Create a dataframe for statistics\n",
    "token_df = pd.DataFrame({\"tokens\": token_number, \"types\": type_number})\n",
    "print(token_df.to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    |   tokens |   types |\n",
      "|:---|---------:|--------:|\n",
      "| mt |    39040 |    4787 |\n",
      "| el |    31240 |    4751 |\n",
      "| tr |    29578 |    6272 |\n",
      "| sq |    26769 |    4891 |\n",
      "| is |    29644 |    4615 |\n",
      "| uk |    31677 |    6507 |\n",
      "| ca |    27544 |    5314 |\n",
      "| mk |    27639 |    5468 |\n",
      "| hr |    26546 |    6222 |\n",
      "| sl |    26292 |    5763 |\n"
     ]
    }
   ],
   "source": [
    "print(token_df.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | most_frequent_type                                                                                                                       |\n",
      "|:---|:-----------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| ca | [(',', 1080), ('▁de', 1014), ('.', 675), ('s', 648), ('▁i', 564), ('▁la', 559), ('▁a', 529), ('▁que', 438), (\"'\", 360), ('’', 334)]      |\n",
      "| el | [('▁', 1017), ('.', 801), (',', 782), ('▁και', 553), ('ς', 525), ('▁να', 351), ('▁το', 321), ('▁του', 292), ('▁την', 268), ('▁με', 264)] |\n",
      "| hr | [(',', 878), ('.', 766), ('▁i', 546), ('▁u', 430), ('a', 413), ('▁je', 350), ('▁na', 282), ('▁za', 253), ('▁se', 239), ('e', 219)]       |\n",
      "| is | [('.', 1017), ('▁og', 628), ('▁að', 613), (',', 600), ('▁', 528), ('▁í', 434), ('▁á', 388), ('▁er', 357), ('s', 326), ('▁sem', 279)]     |\n",
      "| mk | [(',', 1021), ('▁на', 983), ('.', 738), ('▁и', 619), ('▁за', 475), ('▁да', 378), ('▁во', 376), ('▁се', 365), ('▁', 341), ('▁од', 324)]   |\n",
      "| mt | [('-', 2119), ('ħ', 1807), (',', 884), ('.', 724), ('▁', 717), ('ġ', 519), ('▁l', 504), ('i', 466), (\"'\", 462), ('a', 460)]              |\n",
      "| sl | [(',', 1154), ('.', 805), ('▁je', 455), ('▁in', 443), ('▁v', 373), ('▁na', 317), ('▁za', 296), ('a', 240), ('▁se', 227), ('▁da', 214)]   |\n",
      "| sq | [('▁të', 890), (',', 807), ('▁e', 749), ('.', 641), ('▁në', 420), ('▁dhe', 416), ('▁me', 367), ('▁i', 307), ('t', 268), ('▁për', 266)]   |\n",
      "| tr | [('.', 995), (',', 806), ('▁ve', 439), ('▁bir', 265), (\"'\", 244), ('n', 202), ('▁', 190), ('m', 158), ('i', 144), ('de', 143)]           |\n",
      "| uk | [(',', 1352), ('.', 1031), ('▁', 531), ('▁в', 391), ('▁на', 307), ('▁і', 295), ('▁з', 284), ('▁не', 246), ('у', 239), ('і', 237)]        |\n"
     ]
    }
   ],
   "source": [
    "# Let's see the most frequent tokens\n",
    "most_frequent = {}\n",
    "# Sort the dictionary by values (word counts) in descending order\n",
    "for lang in list(main_dict.keys()):\n",
    "\tmost_frequent[lang] = (sorted(main_dict[lang]['token_overlap']['token_count'].items(), key=lambda x: x[1], reverse=True)[:10])\n",
    "\n",
    "print(pd.DataFrame({\"most_frequent_type\": most_frequent}).to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the main dict\n",
    "with open(\"manual-annotations/multilingual-genre-annotated-test-set.json\", \"w\") as file:\n",
    "\tjson.dump(main_dict, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare train df and test set overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary with all tokens from train set and specific test set, iterate through the tokens and count how many times each ocurrs. Calculate cosine similarity.\n",
    "\n",
    "Do this on label level as well to see whether this explains good performance on some of the labels for Maltese."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosine similarity is a metric used to measure the similarity of two vectors. Specifically, it measures the similarity in the direction or orientation of the vectors ignoring differences in their magnitude or scale. Both vectors need to be part of the same inner product space, meaning they must produce a scalar through inner product multiplication. The similarity of two vectors is measured by the cosine of the angle between them. The similarity can take values between -1 and +1. Smaller angles between vectors produce larger cosine values, indicating greater cosine similarity. \n",
    "\n",
    "Cosine similarity ignores 0-0 matches. Counting 0-0 matches in sparse data would inflate similarity scores. Another commonly used metric that ignores 0-0 matches is Jaccard Similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(x, y):\n",
    "    \n",
    "    # Ensure length of x and y are the same\n",
    "    if len(x) != len(y) :\n",
    "        return None\n",
    "    \n",
    "    # Compute the dot product between x and y\n",
    "    dot_product = np.dot(x, y)\n",
    "    \n",
    "    # Compute the L2 norms (magnitudes) of x and y\n",
    "    magnitude_x = np.sqrt(np.sum(x**2)) \n",
    "    magnitude_y = np.sqrt(np.sum(y**2))\n",
    "    \n",
    "    # Compute the cosine similarity\n",
    "    cosine_similarity = dot_product / (magnitude_x * magnitude_y)\n",
    "    \n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('!', 430), ('!!', 23), ('!!!', 14), ('!!!!', 6), ('!!!!!', 1)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import train token count\n",
    "# Save the dictionary of tokens\n",
    "with open(\"datasets/tokenized_datasets/X-GENRE-train-token-count.json\", \"r\") as train_count_file:\n",
    "\ttrain_count = json.load(train_count_file)\n",
    "\n",
    "list(train_count.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('!', 30),\n",
       " ('!!', 1),\n",
       " ('!\"', 1),\n",
       " ('!),', 1),\n",
       " ('\"', 11),\n",
       " ('\".', 2),\n",
       " ('\"...', 1),\n",
       " ('&', 8),\n",
       " (\"'\", 3),\n",
       " (\"''\", 1)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the main dict for test sets\n",
    "with open(\"manual-annotations/multilingual-genre-annotated-test-set.json\", \"r\") as file:\n",
    "\tmain_dict = json.load(file)\n",
    "\n",
    "list(main_dict[\"sl\"][\"token_overlap\"][\"token_count\"].items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing mt\n",
      "Number of token types for mt: 4787\n",
      "Number of intersecting types: 28226\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>▁boot</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁Trend</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁skills</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁ER</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁Install</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁Ż</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁Bran</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NJE</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁primordial</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             train  test\n",
       "▁boot           11     0\n",
       "▁Trend           2     0\n",
       "set             47     1\n",
       "▁skills         38     0\n",
       "▁ER              2     0\n",
       "▁Install         1     1\n",
       "▁Ż               0     7\n",
       "▁Bran            9     0\n",
       "NJE              3     0\n",
       "▁primordial      1     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity for mt: 0.4142476865826809\n",
      "Processing el\n",
      "Number of token types for el: 4751\n",
      "Number of intersecting types: 30954\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>▁Απριλίου</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁boot</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁Trend</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁skills</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁ER</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁Install</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>έλθει</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁Bran</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NJE</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           train  test\n",
       "▁Απριλίου      0     3\n",
       "▁boot         11     0\n",
       "▁Trend         2     0\n",
       "set           47     0\n",
       "▁skills       38     0\n",
       "▁ER            2     0\n",
       "▁Install       1     0\n",
       "έλθει          0     1\n",
       "▁Bran          9     0\n",
       "NJE            3     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity for el: 0.5273207128330722\n",
      "Processing tr\n",
      "Number of token types for tr: 6272\n",
      "Number of intersecting types: 30846\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>▁boot</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁Trend</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁Neden</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁skills</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁ER</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁Install</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁Bran</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NJE</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁primordial</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             train  test\n",
       "▁boot           11     1\n",
       "▁Trend           2     0\n",
       "set             47     0\n",
       "▁Neden           0     1\n",
       "▁skills         38     0\n",
       "▁ER              2     0\n",
       "▁Install         1     0\n",
       "▁Bran            9     0\n",
       "NJE              3     0\n",
       "▁primordial      1     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity for tr: 0.5938472232210807\n",
      "Processing sq\n",
      "Number of token types for sq: 4891\n",
      "Number of intersecting types: 29168\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>▁boot</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁pavarur</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁Trend</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁skills</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁ER</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁Install</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁Bran</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NJE</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁primordial</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             train  test\n",
       "▁boot           11     0\n",
       "▁pavarur         0     1\n",
       "▁Trend           2     0\n",
       "set             47     1\n",
       "▁skills         38     0\n",
       "▁ER              2     0\n",
       "▁Install         1     0\n",
       "▁Bran            9     0\n",
       "NJE              3     0\n",
       "▁primordial      1     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity for sq: 0.43448915477115685\n",
      "Processing is\n",
      "Number of token types for is: 4615\n",
      "Number of intersecting types: 29518\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>▁boot</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁Trend</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁skills</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁ER</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁Install</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁Bran</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NJE</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁primordial</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TION</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             train  test\n",
       "▁boot           11     0\n",
       "▁Trend           2     0\n",
       "set             47     0\n",
       "▁skills         38     0\n",
       "▁ER              2     0\n",
       "▁Install         1     0\n",
       "▁Bran            9     0\n",
       "NJE              3     0\n",
       "▁primordial      1     0\n",
       "TION            18     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity for is: 0.5251354659540077\n",
      "Processing uk\n",
      "Number of token types for uk: 6507\n",
      "Number of intersecting types: 33121\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>та</th>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁boot</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁Trend</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁skills</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁ER</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁Install</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁Bran</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>фи</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NJE</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          train  test\n",
       "та            0    33\n",
       "▁boot        11     0\n",
       "▁Trend        2     0\n",
       "set          47     1\n",
       "▁skills      38     0\n",
       "▁ER           2     0\n",
       "▁Install      1     0\n",
       "▁Bran         9     0\n",
       "фи            0     1\n",
       "NJE           3     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity for uk: 0.5846121788244142\n",
      "Processing ca\n",
      "Number of token types for ca: 5314\n",
      "Number of intersecting types: 29443\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>▁boot</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁Trend</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁skills</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁ER</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁Install</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁Bran</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NJE</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁primordial</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TION</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             train  test\n",
       "▁boot           11     0\n",
       "▁Trend           2     0\n",
       "set             47     0\n",
       "▁skills         38     0\n",
       "▁ER              2     0\n",
       "▁Install         1     0\n",
       "▁Bran            9     0\n",
       "NJE              3     0\n",
       "▁primordial      1     1\n",
       "TION            18     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity for ca: 0.5254392489246424\n",
      "Processing mk\n",
      "Number of token types for mk: 5468\n",
      "Number of intersecting types: 31837\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>та</th>\n",
       "      <td>0</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁boot</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁Јан</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ензи</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁Trend</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>сметаат</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁skills</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁ER</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁Install</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          train  test\n",
       "та            0   206\n",
       "▁boot        11     0\n",
       "▁Јан          0     1\n",
       "ензи          0     3\n",
       "▁Trend        2     0\n",
       "сметаат       0     5\n",
       "set          47     0\n",
       "▁skills      38     0\n",
       "▁ER           2     0\n",
       "▁Install      1     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity for mk: 0.4225320009293607\n",
      "Processing hr\n",
      "Number of token types for hr: 6222\n",
      "Number of intersecting types: 28864\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>▁boot</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁Essen</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁Trend</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁skills</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁ER</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁Install</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁Bran</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NJE</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁primordial</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             train  test\n",
       "▁boot           11     0\n",
       "▁Essen           0     2\n",
       "▁Trend           2     0\n",
       "set             47     0\n",
       "▁skills         38     0\n",
       "▁ER              2     0\n",
       "▁Install         1     0\n",
       "▁Bran            9     0\n",
       "NJE              3     0\n",
       "▁primordial      1     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity for hr: 0.5662098277228971\n",
      "Processing sl\n",
      "Number of token types for sl: 5763\n",
      "Number of intersecting types: 27507\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>▁boot</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁Trend</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁skills</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁ER</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁Install</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁Bran</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NJE</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁primordial</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TION</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             train  test\n",
       "▁boot           11     0\n",
       "▁Trend           2     0\n",
       "set             47     0\n",
       "▁skills         38     0\n",
       "▁ER              2     0\n",
       "▁Install         1     0\n",
       "▁Bran            9     0\n",
       "NJE              3     1\n",
       "▁primordial      1     0\n",
       "TION            18     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity for sl: 0.6334513674796362\n"
     ]
    }
   ],
   "source": [
    "cosine_sim = {}\n",
    "vector_size = {}\n",
    "\n",
    "for lang in list(main_dict.keys()):\n",
    "\tprint(f\"Processing {lang}\")\n",
    "\t# Get token count for current lang\n",
    "\tcurrent_lang_count = main_dict[lang][\"token_overlap\"][\"token_count\"]\n",
    "\n",
    "\tprint(f\"Number of token types for {lang}: {len(list(current_lang_count.keys()))}\")\n",
    "\n",
    "\t# For each test set, create a vector of token counts. Take only tokens that are present either in train_df or test set.\n",
    "\tintersection_dict = {}\n",
    "\n",
    "\t# First, create a list of tokens that are present in either one or the other list\n",
    "\tintersection_keys = []\n",
    "\tintersection_keys.extend(list(current_lang_count.keys()))\n",
    "\tintersection_keys.extend(list(train_count.keys()))\n",
    "\t# Remove duplicated keys\n",
    "\tintersection_keys = list(set(intersection_keys))\n",
    "\tprint(f\"Number of intersecting types: {len(intersection_keys)}\")\n",
    "\n",
    "\t# Then create a dictionary for 1) train df and 2) test df with counts of token types that occur in either of the datasets\n",
    "\ttrain_intersect_dict = {}\n",
    "\ttest_intersect_dict = {}\n",
    "\n",
    "\tfor i in intersection_keys:\n",
    "\t\ttry:\n",
    "\t\t\ttrain_intersect_dict[i] = train_count[i]\n",
    "\t\texcept:\n",
    "\t\t\ttrain_intersect_dict[i] = 0\n",
    "\t\ttry:\n",
    "\t\t\ttest_intersect_dict[i] = current_lang_count[i]\n",
    "\t\texcept:\n",
    "\t\t\ttest_intersect_dict[i] = 0\n",
    "\n",
    "\n",
    "\t# Create a df with intersecting keys\n",
    "\tintersect_df = pd.DataFrame({\"train\": train_intersect_dict, \"test\": test_intersect_dict})\n",
    "\n",
    "\tdisplay(intersect_df.head(10))\n",
    "\n",
    "\t# Calculate cosine similarity\n",
    "\tcurrent_cosine_sim = cosine_similarity(np.array(intersect_df[\"train\"].to_list()), np.array(intersect_df[\"test\"].to_list()))\n",
    "\n",
    "\tprint(f\"Cosine similarity for {lang}: {current_cosine_sim}\")\n",
    "\n",
    "\t# Add to the main dictionary\n",
    "\tmain_dict[lang][\"token_overlap\"][\"cosine_similarity\"] = current_cosine_sim\n",
    "\tmain_dict[lang][\"token_overlap\"][\"intersection_df\"] = intersect_df.to_dict()\n",
    "\tmain_dict[lang][\"token_overlap\"][\"intersection_vector_size\"] = len(intersection_keys)\n",
    "\n",
    "\t# Add to a dict of results\n",
    "\tcosine_sim[lang] = current_cosine_sim\n",
    "\tvector_size[lang] = len(intersection_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    |   cosine_similarity |   vector_size |\n",
      "|:---|--------------------:|--------------:|\n",
      "| sl |            0.633451 |         27507 |\n",
      "| tr |            0.593847 |         30846 |\n",
      "| uk |            0.584612 |         33121 |\n",
      "| hr |            0.56621  |         28864 |\n",
      "| el |            0.527321 |         30954 |\n",
      "| ca |            0.525439 |         29443 |\n",
      "| is |            0.525135 |         29518 |\n",
      "| sq |            0.434489 |         29168 |\n",
      "| mk |            0.422532 |         31837 |\n",
      "| mt |            0.414248 |         28226 |\n"
     ]
    }
   ],
   "source": [
    "# Show results\n",
    "cosine_sim_df = pd.DataFrame({\"cosine_similarity\": cosine_sim, \"vector_size\": vector_size}).sort_values(by=\"cosine_similarity\", ascending=False)\n",
    "print(cosine_sim_df.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['overlap_percentage', 'token_list', 'overlap_token_list', 'token_count', 'cosine_similarity', 'intersection_df', 'intersection_vector_size'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_dict[\"sl\"][\"token_overlap\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the main dict\n",
    "with open(\"manual-annotations/multilingual-genre-annotated-test-set.json\", \"w\") as file:\n",
    "\tjson.dump(main_dict, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crosslingual_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
